{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmvmnL3yTroz"
      },
      "source": [
        "\n",
        "Loading the CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlHjCpIDYpnN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipgma90sTmo9",
        "outputId": "3da9b00d-53e9-49f9-9397-2d5d98bd63dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data Augmentation and Normalization for CIFAR-10\n",
        "# Enhanced Data Augmentation and Normalization for CIFAR-10\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "}\n",
        "\n",
        "\n",
        "# Load CIFAR-10 Dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform['train'])\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform['test'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzqCJTehToYz"
      },
      "outputs": [],
      "source": [
        "class IntermediateBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_layers, kernel_size=3, activation=nn.ReLU()):\n",
        "        super(IntermediateBlock, self).__init__()\n",
        "        self.conv_layers = nn.ModuleList([])\n",
        "        for _ in range(num_layers):\n",
        "            self.conv_layers.append(nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size//2),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                activation\n",
        "            ))\n",
        "        self.fc = nn.Linear(in_channels, num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        m = x.mean([2, 3])  # Compute mean separately for each color channel\n",
        "        a = torch.softmax(self.fc(m), dim=1)  # Calculate 'a' using a fully connected layer\n",
        "        x_prime = sum(a[:, i].view(-1, 1, 1, 1) * conv(x) for i, conv in enumerate(self.conv_layers))\n",
        "\n",
        "        return x_prime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF_E-I0Emv5y"
      },
      "outputs": [],
      "source": [
        "class OutputBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, hidden_layers=[]):\n",
        "        super(OutputBlock, self).__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc_layers = nn.ModuleList()\n",
        "\n",
        "        # Add fully connected layers\n",
        "        input_size = in_channels\n",
        "        for hidden_size in hidden_layers:\n",
        "            self.fc_layers.append(nn.Linear(input_size, hidden_size))\n",
        "            input_size = hidden_size\n",
        "        self.fc_layers.append(nn.Linear(input_size, num_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Reduce spatial dimensions to 1x1 using adaptive average pooling\n",
        "        x = self.avgpool(x)\n",
        "\n",
        "        # Flatten the tensor to a vector\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass through fully connected layers\n",
        "        for fc_layer in self.fc_layers:\n",
        "            x = fc_layer(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDBMc5qumv5y"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "epochs = 30\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "142ecU7gzOu6",
        "outputId": "30f20c59-9ba4-480d-9b3d-c50ec8f4fd38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([1, 10])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1702400440653/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        }
      ],
      "source": [
        "class Model_1(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Model_1, self).__init__()\n",
        "        self.layer1 = IntermediateBlock(3, 64, 2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer2 = IntermediateBlock(64, 128, 2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer3 = IntermediateBlock(128, 256, 3)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.layer4 = IntermediateBlock(256, 512, 3)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.output_block = OutputBlock(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.output_block(x)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model_1().to(device)\n",
        "input_tensor = torch.randn(1, 3, 32, 32).to(device)  # Example input tensor\n",
        "output = model(input_tensor)\n",
        "print(\"Output shape:\", output.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvUJBUbPmv5z"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jd5xQILxmv5z"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-_-FJP_mv5z"
      },
      "outputs": [],
      "source": [
        "# Define training and testing functions\n",
        "\n",
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.squeeze()).sum().item()\n",
        "\n",
        "    return train_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "def test(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets.squeeze())\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets.squeeze()).sum().item()\n",
        "\n",
        "    return test_loss / len(test_loader), 100. * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwnolWbJmv5z",
        "outputId": "6daee1b1-13eb-400a-ed62-ed522a2e33df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Train Loss: 1.3713, Train Acc: 50.39%, Test Loss: 1.1872, Test Acc: 58.57%\n",
            "Epoch [2/50], Train Loss: 1.0059, Train Acc: 64.27%, Test Loss: 1.0465, Test Acc: 62.88%\n",
            "Epoch [3/50], Train Loss: 0.8668, Train Acc: 69.61%, Test Loss: 1.3041, Test Acc: 56.74%\n",
            "Epoch [4/50], Train Loss: 0.7872, Train Acc: 72.53%, Test Loss: 0.7186, Test Acc: 75.18%\n",
            "Epoch [5/50], Train Loss: 0.7223, Train Acc: 75.11%, Test Loss: 0.9181, Test Acc: 69.50%\n",
            "Epoch [6/50], Train Loss: 0.6881, Train Acc: 76.07%, Test Loss: 0.9531, Test Acc: 69.53%\n",
            "Epoch [7/50], Train Loss: 0.6481, Train Acc: 77.35%, Test Loss: 0.6856, Test Acc: 76.81%\n",
            "Epoch [8/50], Train Loss: 0.6220, Train Acc: 78.41%, Test Loss: 0.6477, Test Acc: 78.03%\n",
            "Epoch [9/50], Train Loss: 0.5910, Train Acc: 79.56%, Test Loss: 0.6732, Test Acc: 77.94%\n",
            "Epoch [10/50], Train Loss: 0.5712, Train Acc: 80.00%, Test Loss: 0.7050, Test Acc: 77.01%\n",
            "Epoch [11/50], Train Loss: 0.5453, Train Acc: 81.02%, Test Loss: 0.6103, Test Acc: 79.85%\n",
            "Epoch [12/50], Train Loss: 0.5361, Train Acc: 81.36%, Test Loss: 0.5773, Test Acc: 80.19%\n",
            "Epoch [13/50], Train Loss: 0.5138, Train Acc: 82.21%, Test Loss: 0.6121, Test Acc: 79.81%\n",
            "Epoch [14/50], Train Loss: 0.4974, Train Acc: 82.73%, Test Loss: 0.5596, Test Acc: 81.80%\n",
            "Epoch [15/50], Train Loss: 0.4892, Train Acc: 83.11%, Test Loss: 0.4852, Test Acc: 83.56%\n",
            "Epoch [16/50], Train Loss: 0.4739, Train Acc: 83.53%, Test Loss: 0.6233, Test Acc: 79.85%\n",
            "Epoch [17/50], Train Loss: 0.4569, Train Acc: 84.30%, Test Loss: 0.5679, Test Acc: 82.24%\n",
            "Epoch [18/50], Train Loss: 0.4479, Train Acc: 84.57%, Test Loss: 0.6244, Test Acc: 80.04%\n",
            "Epoch [19/50], Train Loss: 0.4371, Train Acc: 84.70%, Test Loss: 0.4830, Test Acc: 83.62%\n",
            "Epoch [20/50], Train Loss: 0.4234, Train Acc: 85.39%, Test Loss: 0.4600, Test Acc: 84.26%\n",
            "Epoch [21/50], Train Loss: 0.4175, Train Acc: 85.53%, Test Loss: 0.4933, Test Acc: 84.38%\n",
            "Epoch [22/50], Train Loss: 0.4109, Train Acc: 85.75%, Test Loss: 0.5103, Test Acc: 83.40%\n",
            "Epoch [23/50], Train Loss: 0.4027, Train Acc: 85.95%, Test Loss: 0.4841, Test Acc: 83.78%\n",
            "Epoch [24/50], Train Loss: 0.3970, Train Acc: 86.29%, Test Loss: 0.5536, Test Acc: 82.33%\n",
            "Epoch [25/50], Train Loss: 0.3853, Train Acc: 86.65%, Test Loss: 0.5373, Test Acc: 82.98%\n",
            "Epoch [26/50], Train Loss: 0.3823, Train Acc: 86.58%, Test Loss: 0.4838, Test Acc: 84.19%\n",
            "Epoch [27/50], Train Loss: 0.3662, Train Acc: 87.47%, Test Loss: 0.4612, Test Acc: 85.02%\n",
            "Epoch [28/50], Train Loss: 0.3719, Train Acc: 87.32%, Test Loss: 0.4419, Test Acc: 85.35%\n",
            "Epoch [29/50], Train Loss: 0.3638, Train Acc: 87.41%, Test Loss: 0.5430, Test Acc: 83.41%\n",
            "Epoch [30/50], Train Loss: 0.3583, Train Acc: 87.42%, Test Loss: 0.5272, Test Acc: 83.53%\n",
            "Epoch [31/50], Train Loss: 0.2780, Train Acc: 90.45%, Test Loss: 0.3462, Test Acc: 88.79%\n",
            "Epoch [32/50], Train Loss: 0.2546, Train Acc: 91.32%, Test Loss: 0.3405, Test Acc: 88.74%\n",
            "Epoch [33/50], Train Loss: 0.2422, Train Acc: 91.81%, Test Loss: 0.3411, Test Acc: 88.88%\n",
            "Epoch [34/50], Train Loss: 0.2300, Train Acc: 92.17%, Test Loss: 0.3373, Test Acc: 89.29%\n",
            "Epoch [35/50], Train Loss: 0.2241, Train Acc: 92.27%, Test Loss: 0.3334, Test Acc: 89.36%\n",
            "Epoch [36/50], Train Loss: 0.2170, Train Acc: 92.49%, Test Loss: 0.3398, Test Acc: 88.95%\n",
            "Epoch [37/50], Train Loss: 0.2102, Train Acc: 92.72%, Test Loss: 0.3368, Test Acc: 89.17%\n",
            "Epoch [38/50], Train Loss: 0.2070, Train Acc: 92.86%, Test Loss: 0.3377, Test Acc: 89.29%\n",
            "Epoch [39/50], Train Loss: 0.2021, Train Acc: 93.16%, Test Loss: 0.3363, Test Acc: 89.50%\n",
            "Epoch [40/50], Train Loss: 0.1959, Train Acc: 93.33%, Test Loss: 0.3336, Test Acc: 89.38%\n",
            "Epoch [41/50], Train Loss: 0.1904, Train Acc: 93.51%, Test Loss: 0.3399, Test Acc: 89.26%\n",
            "Epoch [42/50], Train Loss: 0.1863, Train Acc: 93.51%, Test Loss: 0.3333, Test Acc: 89.36%\n",
            "Epoch [43/50], Train Loss: 0.1828, Train Acc: 93.68%, Test Loss: 0.3380, Test Acc: 89.52%\n"
          ]
        }
      ],
      "source": [
        "# Training and testing loop\n",
        "num_epochs = 50\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByJdKeVaUWvL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs + 1), epoch_losses, label='Average Epoch Loss')\n",
        "plt.title('Training Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs + 1), train_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs + 1), test_accuracies, label='Testing Accuracy')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Final Testing Accuracy: {best_accuracy:.2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pclqPbRmv5z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}